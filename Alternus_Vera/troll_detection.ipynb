{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling hateness, offensiveness in text\n",
    "### Swetha Chandrasekar\n",
    "012497628 <br>\n",
    "swetha.chandrasekar@sjsu.edu\n",
    "### Project Alternus vera\n",
    "### factor: Trollness\n",
    "<h3> In this note book, for the project of Alternus vera, <br><br><br>\n",
    "-> <font color=orange> In section 1, we will define and model the factor of <font color=red><u><i>troll</i></u></font>.\n",
    "This signal will be used in the polynomial for fake news prediction.</font> <br><br>\n",
    "\n",
    "<font color=blue>\n",
    "-> In Section 2, we will use the signal modeled after troll coefficients (weights) to predict fake news.<br>\n",
    "</font>\n",
    " </h3>\n",
    " \n",
    "### Formal Business Problem Statement: \n",
    "\"\n",
    "\n",
    "<i><u>\n",
    "Given the headline text of article can we predict whether it is a troll or not? </u></i>\n",
    "\n",
    "## What is a troll?\n",
    "Troll is internet account that incites or provokes people on internet by making insulting insensitive comments.\n",
    "They have the ability to hijack a conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 (modelling troll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred from https://www.kaggle.com/alisaeidi92/a-very-simple-nlp-model-0-75-accuracy\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      annotation  \\\n",
       "0  {'notes': '', 'label': ['1']}   \n",
       "1  {'notes': '', 'label': ['1']}   \n",
       "2  {'notes': '', 'label': ['1']}   \n",
       "3  {'notes': '', 'label': ['1']}   \n",
       "4  {'notes': '', 'label': ['1']}   \n",
       "\n",
       "                                             content  extras  \n",
       "0                             Get fucking real dude.     NaN  \n",
       "1   She is as dirty as they come  and that crook ...     NaN  \n",
       "2   why did you fuck it up. I could do it all day...     NaN  \n",
       "3   Dude they dont finish enclosing the fucking s...     NaN  \n",
       "4   WTF are you talking about Men? No men thats n...     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('Dataset for Detection of Cyber-Trolls.json', lines= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Total number of custom documents: 20001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from fastai import *\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.tabular import *\n",
    "from fastai.vision import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "### performing stemming\n",
    "from nltk import PorterStemmer \n",
    "stemmer = PorterStemmer()\n",
    "def lemmatize_stemming(text):\n",
    "    return text\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            if 'object' in token.strip() or 'dtype' in token.strip() or 'unknown' in token.strip():\n",
    "                continue\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "word_vector_input_dataset = df.content.tolist() # tweets1.tweet.tolist()\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "data = word_vector_input_dataset\n",
    "tagged_data = []\n",
    "exception_count = 0\n",
    "for i, _d in enumerate(data):\n",
    "    try:\n",
    "        tagged_data.append(TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]))\n",
    "    except:\n",
    "        exception_count+=1\n",
    "### Train doc2vec embeddings \n",
    "print (\"Total number of custom documents:\",len(tagged_data))\n",
    "max_epochs = 10\n",
    "vec_size = 10\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=10,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"troll.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "corpus = []\n",
    "\n",
    "for i in range (0, len(df)):                              \n",
    "    review = re.sub('[^a-zA-Z]',' ',df['content'][i])      \n",
    "    review = review.lower()                                 \n",
    "    review = review.split()                                 \n",
    "    review = ' '.join(review)                               \n",
    "    corpus.append(review)                                   \n",
    "\n",
    "corpus\n",
    "\n",
    "bow_transformer =  CountVectorizer()\n",
    "bow_transformer = bow_transformer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16332\n"
     ]
    }
   ],
   "source": [
    "print(len(bow_transformer.vocabulary_))\n",
    "messages_bow = bow_transformer.transform(corpus)  \n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)  \n",
    "X = tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(0,len(df)):\n",
    "    y.append(df.annotation[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train,y_train)      #training the model\n",
    "y_pred = classifier.predict(X_test)  #Predicting our test label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7546490701859628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 (Using them to predict fake news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "headers = ['id','label','statement','subject',\n",
    "           'speaker','job_title', 'state', \n",
    "           'affliation','barely_true','false',\n",
    "           'half_true', 'mostly_true','pants_on_fire', \n",
    "           'venue']\n",
    "print (len(headers))\n",
    "liar_train_df = pd.read_csv('../train.tsv', names=headers, delimiter='\\t')\n",
    "liar_valid_df = pd.read_csv('../valid.tsv', names=headers, delimiter='\\t')\n",
    "liar_test_df = pd.read_csv('../test.tsv',names=headers, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = liar_train_df.statement.tolist()\n",
    "label = liar_train_df.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.083257,  0.046213,  0.258332,  0.113605, -0.014138, -0.292804,  0.114289, -0.044698,  0.098953,  0.124028],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "training_vector = []\n",
    "text = \"Lol! thats the dumbest\"\n",
    "dvmodel= Doc2Vec.load(\"troll.model\") ### Using a earlier trained model d2v.model \n",
    "test_sentence= [dvmodel.infer_vector(word_tokenize(text))]\n",
    "print (test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for statement in statements:\n",
    "    training_vector.append(dvmodel.infer_vector(statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.537018</td>\n",
       "      <td>-0.321614</td>\n",
       "      <td>0.169376</td>\n",
       "      <td>-1.492093</td>\n",
       "      <td>1.012527</td>\n",
       "      <td>-1.203823</td>\n",
       "      <td>-1.298267</td>\n",
       "      <td>-1.100511</td>\n",
       "      <td>0.718208</td>\n",
       "      <td>2.492185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.118141</td>\n",
       "      <td>-0.561401</td>\n",
       "      <td>-0.191981</td>\n",
       "      <td>-1.552008</td>\n",
       "      <td>1.206618</td>\n",
       "      <td>-1.649394</td>\n",
       "      <td>-2.094774</td>\n",
       "      <td>-1.910305</td>\n",
       "      <td>0.455243</td>\n",
       "      <td>2.602982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.866397</td>\n",
       "      <td>-0.562808</td>\n",
       "      <td>-0.165545</td>\n",
       "      <td>-0.546028</td>\n",
       "      <td>1.048599</td>\n",
       "      <td>-1.869399</td>\n",
       "      <td>-1.368361</td>\n",
       "      <td>-1.958817</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>1.110466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.365077</td>\n",
       "      <td>-0.201160</td>\n",
       "      <td>-0.363634</td>\n",
       "      <td>-0.551486</td>\n",
       "      <td>0.916340</td>\n",
       "      <td>-1.184154</td>\n",
       "      <td>-0.843864</td>\n",
       "      <td>-1.317291</td>\n",
       "      <td>-0.010330</td>\n",
       "      <td>2.004547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.945798</td>\n",
       "      <td>-0.490730</td>\n",
       "      <td>0.100463</td>\n",
       "      <td>-0.543795</td>\n",
       "      <td>0.561219</td>\n",
       "      <td>-1.081011</td>\n",
       "      <td>-1.115513</td>\n",
       "      <td>-1.303067</td>\n",
       "      <td>0.054405</td>\n",
       "      <td>1.758264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  2.537018 -0.321614  0.169376 -1.492093  1.012527 -1.203823 -1.298267   \n",
       "1  3.118141 -0.561401 -0.191981 -1.552008  1.206618 -1.649394 -2.094774   \n",
       "2  1.866397 -0.562808 -0.165545 -0.546028  1.048599 -1.869399 -1.368361   \n",
       "3  2.365077 -0.201160 -0.363634 -0.551486  0.916340 -1.184154 -0.843864   \n",
       "4  1.945798 -0.490730  0.100463 -0.543795  0.561219 -1.081011 -1.115513   \n",
       "\n",
       "          7         8         9  label  \n",
       "0 -1.100511  0.718208  2.492185      0  \n",
       "1 -1.910305  0.455243  2.602982      1  \n",
       "2 -1.958817 -0.127119  1.110466      1  \n",
       "3 -1.317291 -0.010330  2.004547      0  \n",
       "4 -1.303067  0.054405  1.758264      1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troll_df= pd.DataFrame(training_vector)\n",
    "troll_df['label'] = pd.Series(label)\n",
    "troll_df['label'] = troll_df.label.apply(lambda x: 0 if 'barely' in str(x) or 'false' in str(x) else 1)\n",
    "troll_df.columns=['0','1','2','3','4','5','6','7','8','9','label']\n",
    "troll_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['0','1','2','3','4','5','6','7','8','9']\n",
    "X = troll_df[features]\n",
    "Y = troll_df[['label']]\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = X.fillna(0);\n",
    "Y = Y.fillna(0);\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_Y = scaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=1, warm_start=False)\n",
      "Score: 0.6123046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, scaled_Y, test_size=0.1, random_state=0)\n",
    "lm = linear_model.LogisticRegression(verbose=1)\n",
    "model = lm.fit(X_train, y_train)\n",
    "print (model)\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "print (\"Score:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
